{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brian Huang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "\n",
    "    def __init__(self, alpha=1):\n",
    "        self.prior = {}\n",
    "        self.per_feature_per_label = {}\n",
    "        self.feature_sum_per_label = {}\n",
    "        self.likelihood = {}\n",
    "        self.posterior = {}\n",
    "        self.alpha = alpha\n",
    "        self.p = None\n",
    "        \n",
    "    def compute_prior(self, y):\n",
    "        #Classifying spam\n",
    "        for spam in y:\n",
    "            if spam in self.prior:\n",
    "                self.prior[spam] += 1.\n",
    "            else:\n",
    "                self.prior[spam] = 1.\n",
    "\n",
    "    #Creating formula method for easier management\n",
    "    def formula(self, Syi, alpha, Sy, p):\n",
    "            return (Syi+alpha) / (Sy+(alpha*p))\n",
    "                \n",
    "    def compute_likelihood(self, X, y): \n",
    "        '''Note: Sy,i is self.per_feature_per_label\n",
    "        and Sy is self.feature_sum_per_label. First\n",
    "        loop goes through to get Sy,i and Sy'''\n",
    "        \n",
    "        #Making this a defaultdict for easy data structure\n",
    "        self.per_feature_per_label = dd(list)\n",
    "        for i, j in zip(X,y):\n",
    "            #getting Sy,i\n",
    "            if j not in self.per_feature_per_label:\n",
    "                self.per_feature_per_label[j] = 0.\n",
    "            self.per_feature_per_label[j] += i\n",
    "            #getting Sy\n",
    "            if j in self.per_feature_per_label:\n",
    "                self.feature_sum_per_label[j] = sum(self.per_feature_per_label[j])\n",
    "        \n",
    "        #p is the number of features\n",
    "        p = len(self.per_feature_per_label)\n",
    "        \n",
    "        #creating data structure for likelihood matrix\n",
    "        self.likelihood = dd(list)\n",
    "        \n",
    "        #loop through each y_value (0, 1)\n",
    "        for y_value in self.feature_sum_per_label:\n",
    "            #if no y is stored in likelihood, we set it to 0\n",
    "            #print self.likelihood[y_value]\n",
    "            if y_value not in self.likelihood:\n",
    "                self.likelihood[y_value] = []\n",
    "            #else, we store the likehood probabilities (from formula)\n",
    "            self.likelihood[y_value].append(self.formula(np.asarray(self.per_feature_per_label[y_value]).T,\n",
    "                                                    self.alpha,\n",
    "                                                    np.asarray(self.feature_sum_per_label[y_value]),\n",
    "                                                    p))\n",
    "        \n",
    "        '''This piece of code restructured the data\n",
    "        in the likelihood dictionary. My fault for not\n",
    "        storing it right the first time...'''\n",
    "        x1 = []\n",
    "        x2 = []\n",
    "        \n",
    "        for k,v in self.likelihood.items():\n",
    "            if k == 0.0:\n",
    "                #loop through key to get array\n",
    "                for item in v:\n",
    "                    #loop through element of array\n",
    "                    for ele in item:\n",
    "                        #append elements individually\n",
    "                        x1.append(ele)\n",
    "            if k == 1.0:\n",
    "                for item in v:\n",
    "                    for ele in item:\n",
    "                        x2.append(ele)\n",
    "        #convert new list into array to avoid double lists\n",
    "        x1, x2 = np.asarray(x1), np.asarray(x2)\n",
    "        \n",
    "        #updating the dictionary\n",
    "        self.likelihood[0] = x1\n",
    "        self.likelihood[1] = x2\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.p = X.shape[1]\n",
    "        self.compute_prior(y)\n",
    "        self.compute_likelihood(X, y)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        classification = []\n",
    "        for ele in X:\n",
    "            lst = []\n",
    "            for key in self.prior:\n",
    "                prob = np.sum(ele*np.log(self.likelihood.get(key)))+np.log((self.prior[key])/np.sum(self.prior.values()))\n",
    "                lst.append(prob)\n",
    "            classification.append(np.argmax(lst))\n",
    "        return classification\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        diff = self.predict(X) - y\n",
    "        score = 0.\n",
    "        for item in diff:\n",
    "            score += np.absolute(item)\n",
    "        return 1.-score/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('spam.csv', delimiter=',')\n",
    "y = data[:, -1]\n",
    "X = data[:, 0:-1]\n",
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb.compute_likelihood(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<type 'list'>, {0.0: array([  3.85334561e-04,   1.27765380e-03,   1.04863562e-03,\n",
       "         6.49524399e-06,   9.46658413e-04,   2.34334177e-04,\n",
       "         5.08388550e-05,   2.02344633e-04,   2.00435368e-04,\n",
       "         8.74274815e-04,   1.15173592e-04,   2.80076044e-03,\n",
       "         3.23676539e-04,   2.23159363e-04,   4.52795251e-05,\n",
       "         3.85896110e-04,   2.54175557e-04,   5.09605238e-04,\n",
       "         6.63134462e-03,   4.14235589e-05,   2.29130495e-03,\n",
       "         2.37890651e-04,   3.88591542e-05,   9.13077815e-05,\n",
       "         4.67504077e-03,   2.25630176e-03,   6.60485825e-03,\n",
       "         1.01327678e-03,   8.51438511e-04,   8.67405206e-04,\n",
       "         5.55221692e-04,   4.05306968e-04,   7.89817925e-04,\n",
       "         4.07815218e-04,   8.86198361e-04,   7.41206546e-04,\n",
       "         1.03382945e-03,   9.95812623e-05,   6.36870840e-04,\n",
       "         4.35630586e-04,   3.77753657e-04,   1.13331713e-03,\n",
       "         3.70210189e-04,   6.62739506e-04,   2.17158281e-03,\n",
       "         1.50058854e-03,   4.46243852e-05,   2.69206337e-04,\n",
       "         2.64270326e-04,   8.29437042e-04,   1.20249990e-04,\n",
       "         5.75838008e-04,   6.26613221e-05,   1.15184822e-04,\n",
       "         1.24081903e-02,   9.50570534e-02,   8.42663380e-01]), 1.0: array([  2.56931114e-04,   2.77619820e-04,   6.79501645e-04,\n",
       "         2.77656896e-04,   8.64624780e-04,   2.94804794e-04,\n",
       "         4.63744022e-04,   3.50706938e-04,   2.86712840e-04,\n",
       "         5.89952545e-04,   1.99953750e-04,   9.25152223e-04,\n",
       "         2.42156115e-04,   1.41372825e-04,   1.89275708e-04,\n",
       "         8.72030818e-04,   4.84080501e-04,   5.37387289e-04,\n",
       "         3.80647167e-03,   3.46304100e-04,   2.32062955e-03,\n",
       "         4.00945642e-04,   4.16100676e-04,   3.58669124e-04,\n",
       "         3.03007977e-05,   1.63414825e-05,   3.53153989e-06,\n",
       "         3.25161206e-05,   2.07628592e-06,   1.09561159e-05,\n",
       "         3.06808322e-06,   1.79821191e-06,   2.53974260e-05,\n",
       "         3.91157437e-06,   1.25689451e-05,   5.05260472e-05,\n",
       "         7.39769551e-05,   8.84275344e-06,   2.18102713e-05,\n",
       "         6.26315356e-05,   1.01960469e-06,   5.03313953e-06,\n",
       "         1.51272260e-05,   1.14195726e-05,   2.11141594e-04,\n",
       "         2.56755000e-05,   2.97539188e-06,   4.45845325e-06,\n",
       "         3.54998547e-05,   1.84050697e-04,   1.47045535e-05,\n",
       "         8.64217866e-04,   2.94136489e-04,   1.33479231e-04,\n",
       "         1.59978257e-02,   1.75433184e-01,   7.90873992e-01])})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
